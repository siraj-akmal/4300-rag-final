{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d4df28-4ee6-47b7-a8f9-92dc34c532ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (5.0.9)\n",
      "Requirement already satisfied: configparser in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (7.2.0)\n",
      "Requirement already satisfied: httplib2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (5.3.2)\n",
      "Requirement already satisfied: nipype in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (1.9.2)\n",
      "Requirement already satisfied: numpy in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (2.0.3)\n",
      "Requirement already satisfied: pyxnat in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (1.6.3)\n",
      "Requirement already satisfied: scipy in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from fitz) (1.11.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from httplib2->fitz) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nibabel->fitz) (6.5.2)\n",
      "Requirement already satisfied: packaging>=20 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nibabel->fitz) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nibabel->fitz) (4.12.2)\n",
      "Requirement already satisfied: click>=6.6.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (8.0.4)\n",
      "Requirement already satisfied: networkx>=2.5 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (3.1)\n",
      "Requirement already satisfied: prov>=1.5.2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (2.0.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (7.0.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (3.9.0)\n",
      "Requirement already satisfied: acres in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: puremagic in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from nipype->fitz) (1.28)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from pandas->fitz) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from pandas->fitz) (2023.3)\n",
      "Requirement already satisfied: lxml>=4.3 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from pyxnat->fitz) (4.9.3)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from pyxnat->fitz) (2.31.0)\n",
      "Requirement already satisfied: pathlib>=1.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.2->nipype->fitz) (1.16.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests>=2.20->pyxnat->fitz) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests>=2.20->pyxnat->fitz) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests>=2.20->pyxnat->fitz) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests>=2.20->pyxnat->fitz) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1a8b41-b761-4bdc-ab31-44cb666b3230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: frontend in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (0.0.3)\n",
      "Requirement already satisfied: starlette>=0.12.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from frontend) (0.46.1)\n",
      "Requirement already satisfied: uvicorn>=0.7.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from frontend) (0.34.0)\n",
      "Requirement already satisfied: itsdangerous>=1.1.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from frontend) (2.0.1)\n",
      "Requirement already satisfied: aiofiles in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from frontend) (22.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from starlette>=0.12.0->frontend) (4.9.0)\n",
      "Requirement already satisfied: click>=7.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from uvicorn>=0.7.1->frontend) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from uvicorn>=0.7.1->frontend) (0.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6496b867-9cd1-48fd-a8f4-9e698b9fb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Obtaining dependency information for pymupdf from https://files.pythonhosted.org/packages/ae/76/0757056bdcf273de4934681b84acde6e0b61a46b1755038e8d786ac6b368/pymupdf-1.25.4-cp39-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pymupdf-1.25.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.4-cp39-abi3-macosx_11_0_arm64.whl (18.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dac5ae2-5f46-45de-bb8f-e26a79d29882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4300 Notes is where the PDFs are stored, processed_texts is where txt files are saved to\n",
    "PDF_FOLDER = \"4300 Notes\"\n",
    "OUTPUT_FOLDER = \"processed_texts\"\n",
    "\n",
    "#Adjust chunks and chunk size here\n",
    "CHUNK_SIZE = 50  \n",
    "OVERLAP_SIZE = 30  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09bf6ed9-fafd-4b3f-a307-067a6cb4c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed B-trees.pdf → 42 chunks saved.\n",
      "Processed Document DBs and Mongo.pdf → 55 chunks saved.\n",
      "Processed NoSQL Documentation.pdf → 67 chunks saved.\n",
      "Processed AWS Intro.pdf → 39 chunks saved.\n",
      "Processed MongoDB Documentation.pdf → 85 chunks saved.\n",
      "Processed BST_hw.pdf → 30 chunks saved.\n",
      "Processed EC2 & Lambda.pdf → 29 chunks saved.\n",
      "Processed MongoDB Examples.pdf → 36 chunks saved.\n",
      "Processed Neo4j.pdf → 33 chunks saved.\n",
      "Processed MongoDB Aggregation.pdf → 16 chunks saved.\n",
      "Processed B-Trees — CS3 Data Structures & Algorithms.pdf → 180 chunks saved.\n",
      "Processed Redis + Python.pdf → 22 chunks saved.\n",
      "Processed Introduction to Graph Data Model.pdf → 30 chunks saved.\n",
      "Processed BST.pdf → 92 chunks saved.\n",
      "Processed Data Replication.pdf → 47 chunks saved.\n",
      "Processed NoSQL Intro + KV DBs.pdf → 89 chunks saved.\n",
      "Processed B+Tree Walkthrough.pdf → 22 chunks saved.\n",
      "Processed Foundations.pdf → 41 chunks saved.\n",
      "Processed Moving Beyond the Relational Model.pdf → 60 chunks saved.\n",
      "Processed PyMongo.pdf → 9 chunks saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "#Extracting the text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "#Remove extra spaces, newlines and non-ASCII\n",
    "def clean_text(text): \n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \") \n",
    "    text = \" \".join(text.split())  \n",
    "    return text\n",
    "\n",
    "#Split text into chunks with overlap\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def process_pdfs():\n",
    "    for filename in os.listdir(PDF_FOLDER):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(PDF_FOLDER, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            text = clean_text(text) \n",
    "            chunks = chunk_text(text, chunk_size=CHUNK_SIZE, overlap=OVERLAP_SIZE) \n",
    "            \n",
    "            #Save chunks as separate file\n",
    "            for idx, chunk in enumerate(chunks):\n",
    "                chunk_filename = f\"{filename.replace('.pdf', '')}_chunk{idx}.txt\"\n",
    "                output_path = os.path.join(OUTPUT_FOLDER, chunk_filename)\n",
    "                \n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(chunk)\n",
    "                \n",
    "            print(f\"Processed {filename} → {len(chunks)} chunks saved.\")\n",
    "\n",
    "process_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c92e5-a161-4049-af67-06f785c81056",
   "metadata": {},
   "source": [
    "# USING TEST TRANSFORMER TO TEST QUERIES FOR CHUNK SIZE OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e43d5e3-5ef2-4470-815a-e1972f851852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scipy in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: filelock in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sirajakmal/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "950d1ef4-4d21-4a1b-ae52-46e4090e4f9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1863\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1863\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1851\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1851\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1852\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1865\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1865\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1866\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1867\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1868\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load your text chunks (from processed_texts folder)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/__init__.py:14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[1;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[1;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fullname, get_device_name, import_from_string\n\u001b[1;32m     23\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_npu_available\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/model_card.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1851\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1849\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1851\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1852\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1865\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1865\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1866\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1867\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1868\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your text chunks (from processed_texts folder)\n",
    "OUTPUT_FOLDER = \"processed_texts\"  # Folder containing the chunks\n",
    "chunks = []\n",
    "\n",
    "for filename in os.listdir(OUTPUT_FOLDER):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(OUTPUT_FOLDER, filename), 'r', encoding='utf-8') as f:\n",
    "            chunks.append(f.read())\n",
    "\n",
    "# Use a sentence transformer model for embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for all text chunks\n",
    "chunk_embeddings = model.encode(chunks, convert_to_tensor=True)\n",
    "\n",
    "# Function to run queries and get the most similar chunks\n",
    "def run_query(query):\n",
    "    # Encode the query into a vector\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity between the query and the text chunks\n",
    "    similarities = cosine_similarity(query_embedding.cpu().detach().numpy(), chunk_embeddings.cpu().detach().numpy())\n",
    "    \n",
    "    # Get the index of the most similar chunk\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    most_similar_chunk = chunks[most_similar_idx]\n",
    "    \n",
    "    print(f\"Most similar chunk for query '{query}':\\n\")\n",
    "    print(most_similar_chunk)\n",
    "    print(f\"\\nSimilarity Score: {similarities[0][most_similar_idx]}\")\n",
    "    \n",
    "# Example query\n",
    "run_query(\"How to write a NoSQL Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a47f9db-0059-48c0-a095-0ad725e2506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select an embedding model:\n",
      "1: nomic-embed-text\n",
      "2: jina-embeddings-v2-base-en\n",
      "3: granite-embedding:278m\n",
      "Enter the number corresponding to your choice: 1\n",
      "Select an LLM model:\n",
      "1: llama3.2:latest\n",
      "2: mistral\n",
      "Enter the number corresponding to your choice: 1\n",
      "Using LLM model: llama3.2:latest\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "unknown command 'FT.CREATE', with args beginning with: 'embedding_index' 'ON' 'HASH' 'PREFIX' '1' 'doc:' 'SCHEMA' 'text' 'TEXT' 'embedding' 'VECTOR' 'HNSW' '6' 'DIM' '768' 'TYPE' 'FLOA' ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18000\\2869778026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[0mcreate_hnsw_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m     \u001b[0mprocess_text_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"What is redis?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18000\\2869778026.py\u001b[0m in \u001b[0;36mcreate_hnsw_index\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     redis_client.execute_command(\n\u001b[0m\u001b[0;32m     29\u001b[0m         f\"\"\"\n\u001b[0;32m     30\u001b[0m         \u001b[0mFT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCREATE\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mINDEX_NAME\u001b[0m\u001b[1;33m}\u001b[0m \u001b[0mON\u001b[0m \u001b[0mHASH\u001b[0m \u001b[0mPREFIX\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mDOC_PREFIX\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;31m# COMMAND EXECUTION AND PROTOCOL PARSING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36m_execute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m             return conn.retry.call_with_retry(\n\u001b[0m\u001b[0;32m    568\u001b[0m                 lambda: self._send_command_parse_response(\n\u001b[0;32m    569\u001b[0m                     \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\redis\\retry.py\u001b[0m in \u001b[0;36mcall_with_retry\u001b[1;34m(self, do, fail)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_supported_errors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mfailures\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m             return conn.retry.call_with_retry(\n\u001b[1;32m--> 568\u001b[1;33m                 lambda: self._send_command_parse_response(\n\u001b[0m\u001b[0;32m    569\u001b[0m                     \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m                 ),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36m_send_command_parse_response\u001b[1;34m(self, conn, command_name, *args, **options)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_disconnect_raise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36mparse_response\u001b[1;34m(self, connection, command_name, **options)\u001b[0m\n\u001b[0;32m    582\u001b[0m                 \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNEVER_DECODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mEMPTY_RESPONSE\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36mread_response\u001b[1;34m(self, disable_decoding, disconnect_on_error, push_request)\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mresponse\u001b[0m  \u001b[1;31m# avoid creating ref cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResponseError\u001b[0m: unknown command 'FT.CREATE', with args beginning with: 'embedding_index' 'ON' 'HASH' 'PREFIX' '1' 'doc:' 'SCHEMA' 'text' 'TEXT' 'embedding' 'VECTOR' 'HNSW' '6' 'DIM' '768' 'TYPE' 'FLOA' "
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import redis\n",
    "import numpy as np\n",
    "import os\n",
    "from redis.commands.search.query import Query\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Initialize Redis connection\n",
    "redis_client = redis.Redis(host=\"localhost\", port=6379, db=0)\n",
    "\n",
    "# set constants\n",
    "VECTOR_DIM = 768\n",
    "INDEX_NAME = \"embedding_index\"\n",
    "DOC_PREFIX = \"doc:\"\n",
    "DISTANCE_METRIC = \"COSINE\"\n",
    "TEXT_FOLDER = \"processed_texts\"  \n",
    "selected_model = None\n",
    "jina_model = None\n",
    "selected_llm_model = None\n",
    "\n",
    "#clear redis database if reindexing\n",
    "def create_hnsw_index():\n",
    "    try:\n",
    "        redis_client.execute_command(f\"FT.DROPINDEX {INDEX_NAME} DD\")\n",
    "    except redis.exceptions.ResponseError:\n",
    "        pass\n",
    "    \n",
    "    redis_client.execute_command(\n",
    "        f\"\"\"\n",
    "        FT.CREATE {INDEX_NAME} ON HASH PREFIX 1 {DOC_PREFIX}\n",
    "        SCHEMA text TEXT\n",
    "        embedding VECTOR HNSW 6 DIM {VECTOR_DIM} TYPE FLOAT32 DISTANCE_METRIC {DISTANCE_METRIC}\n",
    "        \"\"\"\n",
    "    )\n",
    "    print(\"Index created successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Generate an embedding for the given text using the selected embedding model.\n",
    "\n",
    "    This function uses either the Jina embeddings model or the Ollama embeddings\n",
    "    model based on the global EMBEDDING_MODEL setting.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of floats representing the embedding vector for the input text.\n",
    "    \"\"\"\n",
    "    if EMBEDDING_MODEL == \"jina-embeddings-v2-base-en\":\n",
    "        return jina_model.encode([text])[0].tolist()\n",
    "    else:\n",
    "        response = ollama.embeddings(model=EMBEDDING_MODEL, prompt=text)\n",
    "        return response[\"embedding\"]\n",
    "\n",
    "\n",
    "def store_embedding(doc_id: str, text: str, embedding: list):\n",
    "    key = f\"{DOC_PREFIX}{doc_id}\"\n",
    "    redis_client.hset(\n",
    "        key,\n",
    "        mapping={\n",
    "            \"text\": text,\n",
    "            \"embedding\": np.array(embedding, dtype=np.float32).tobytes(),  # Store as byte array\n",
    "        },\n",
    "    )\n",
    "    print(f\"Stored embedding for: {doc_id}\")\n",
    "\n",
    "def process_text_files():\n",
    "    \"\"\"\n",
    "    This function processes all text files in the specified folder, reads their content,\n",
    "    generates embeddings for the text using the selected embedding model, and stores the\n",
    "    embeddings along with the text content in Redis.\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(TEXT_FOLDER):\n",
    "        print(f\"Folder '{TEXT_FOLDER}' not found.\")\n",
    "        return\n",
    "\n",
    "    text_files = [f for f in os.listdir(TEXT_FOLDER) if f.endswith(\".txt\")]\n",
    "    if not text_files:\n",
    "        print(\"No text files found.\")\n",
    "        return\n",
    "\n",
    "    for filename in text_files:\n",
    "        filepath = os.path.join(TEXT_FOLDER, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            embedding = get_embedding(text)\n",
    "            store_embedding(filename, text, embedding)\n",
    "\n",
    "def query_llm(query: str, matching_chunks: list) -> str:\n",
    "    \"\"\"\n",
    "    Query the Language Model (LLM) with a given question and relevant context.\n",
    "\n",
    "    This function prepares a prompt by combining the user's query and relevant context\n",
    "    from matching chunks. It then sends this prompt to the LLM for processing and returns\n",
    "    the model's response.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The user's question or input to be answered by the LLM.\n",
    "    matching_chunks (list): A list of text chunks that provide relevant context for the query.\n",
    "    \"\"\"\n",
    "    context = \"\\n\\n\".join([f\"Chunk {i+1}: {chunk}\" for i, chunk in enumerate(matching_chunks)])\n",
    "    prompt_to_send = (\n",
    "        f\"User's Question: {query}\\n\\n\"\n",
    "        f\"Relevant Context (if applicable):\\n{context}\\n\\n\"\n",
    "        \"Your task: Answer the user's question as clearly and accurately as possible.\"\n",
    "        \"If the question is unclear or not actually a question, state that explicitly.\"\n",
    "    )\n",
    "    response = ollama.chat(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant with expertise in computer science.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_to_send}\n",
    "        ],\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "def perform_knn_search(query_text: str, k: int = 2):\n",
    "    \"\"\"\n",
    "    Perform a K-Nearest Neighbors (KNN) search on the Redis index using the given query text.\n",
    "\n",
    "    This function embeds the query text, searches for similar embeddings in the Redis index,\n",
    "    retrieves matching text chunks, and generates a response using a language model.\n",
    "\n",
    "    Parameters:\n",
    "    query_text (str): The text query to search for in the index.\n",
    "    k (int, optional): The number of nearest neighbors to retrieve. Defaults to 2.\n",
    "\n",
    "    \"\"\"\n",
    "    embedding = get_embedding(query_text)\n",
    "    q = (\n",
    "        Query(f\"*=>[KNN {k} @embedding $vec AS vector_distance]\")\n",
    "        .sort_by(\"vector_distance\")\n",
    "        .return_fields(\"text\", \"vector_distance\")\n",
    "        .dialect(2)\n",
    "    )\n",
    "    res = redis_client.ft(INDEX_NAME).search(\n",
    "        q, query_params={\"vec\": np.array(embedding, dtype=np.float32).tobytes()}\n",
    "    )\n",
    "    matching_chunks = [doc.text for doc in res.docs]\n",
    "    if not matching_chunks:\n",
    "        print(\"No relevant matches found.\")\n",
    "        return\n",
    "    print(f\"\\nTop {len(matching_chunks)} matching chunks retrieved:\")\n",
    "    for i, chunk in enumerate(matching_chunks):\n",
    "        print(f\"\\nChunk {i+1}: {chunk[:300]}...\")  # Display first 300 characters\n",
    "    response = query_llm(query_text, matching_chunks)\n",
    "    print(f\"\\nResponse from {LLM_MODEL}:\\n{response}\\n\")\n",
    "\n",
    "\n",
    "# Prompt user to select an embedding model\n",
    "embedding_models = {\n",
    "    \"1\": \"nomic-embed-text\",\n",
    "    \"2\": \"jina-embeddings-v2-base-en\",\n",
    "    \"3\": \"granite-embedding:278m\",\n",
    "}\n",
    "\n",
    "print(\"Select an embedding model:\")\n",
    "for key, model in embedding_models.items():\n",
    "    print(f\"{key}: {model}\")\n",
    "\n",
    "while selected_model not in embedding_models:\n",
    "    selected_model = input(\"Enter the number corresponding to your choice: \")\n",
    "\n",
    "EMBEDDING_MODEL = embedding_models[selected_model]\n",
    "\n",
    "# If Jina embeddings are selected, load the model\n",
    "if EMBEDDING_MODEL == \"jina-embeddings-v2-base-en\":\n",
    "    jina_model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v2-base-en\", trust_remote_code=True)\n",
    "\n",
    "# Prompt user to select an LLM model\n",
    "llm_models = {\n",
    "    \"1\": \"llama3.2:latest\",\n",
    "    \"2\": \"mistral\",\n",
    "}\n",
    "\n",
    "print(\"Select an LLM model:\")\n",
    "for key, model in llm_models.items():\n",
    "    print(f\"{key}: {model}\")\n",
    "\n",
    "while selected_llm_model not in llm_models:\n",
    "    selected_llm_model = input(\"Enter the number corresponding to your choice: \")\n",
    "\n",
    "LLM_MODEL = llm_models[selected_llm_model]\n",
    "print(f\"Using LLM model: {LLM_MODEL}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_hnsw_index()\n",
    "    process_text_files()\n",
    "    query = \"What is redis?\"\n",
    "    perform_knn_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f911b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.50.0-py3-none-any.whl (10.2 MB)\n",
      "     --------------------------------------- 10.2/10.2 MB 22.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Collecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "     ------------------------------------- 308.9/308.9 kB 18.7 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.26.0\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "     ------------------------------------- 469.0/469.0 kB 28.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 51.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "     ---------------------------------------- 193.6/193.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryanw\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "Successfully installed fsspec-2025.3.0 huggingface-hub-0.29.3 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.50.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
